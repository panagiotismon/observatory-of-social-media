{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3919e547",
   "metadata": {},
   "source": [
    "# Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09cf6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import AutoModelForSequenceClassification, pipeline, AutoTokenizer\n",
    "import preprocessor as p\n",
    "from geopy.geocoders import Nominatim\n",
    "from os import listdir\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7240f5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bfbbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_KEY = \"xxxxxxxxxxxxx\"\n",
    "APP_SECRET = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "SAMPLES_DIR = \"./data\"\n",
    "MAX_SAMPLES = 2 # Limit of the top n lines to read in each file sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0f7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_website = pd.read_csv(\"websites.csv\")\n",
    "trust_websites_map: map = {}\n",
    "sites = list(trust_website[\"site\"])\n",
    "site_scores = list(trust_website[\"trust\"])\n",
    "for i in range(0, len(sites)):\n",
    "    trust_websites_map.setdefault(sites[i], site_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e3a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_trust_score(external_url: str):\n",
    "    if external_url:\n",
    "        return trust_websites_map.get(external_url, 0)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310c9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bearer_token():\n",
    "    url = 'https://api.twitter.com/oauth2/token'\n",
    "    auth = (APP_KEY, APP_SECRET)\n",
    "    data = {'grant_type': 'client_credentials'}\n",
    "\n",
    "    response = requests.post(url, auth=auth, data=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a91e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_external_url_from_tweet(tweet)->set:\n",
    "    external_urls_objects = tweet['entities'].get(\"urls\", None)\n",
    "    if external_urls_objects:\n",
    "        for url_object in external_urls_objects:\n",
    "            try:\n",
    "                url = url_object['display_url'].split('/', 1)[0]\n",
    "                if \"twitter.com\" not in url:\n",
    "                    return url\n",
    "            except Exception as ex:\n",
    "                continue\n",
    "        return None;\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d39ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_from_user(user):\n",
    "    followers_count = user[\"public_metrics\"].get(\"followers_count\", None)\n",
    "    tweet_count = user[\"public_metrics\"].get(\"tweet_count\", None)\n",
    "    \n",
    "    return (followers_count, tweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a4758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags_texts(hashtags: list):\n",
    "    hashtags_list = []\n",
    "    for hashtag in hashtags:\n",
    "        hashtags_list.append(hashtag.get(\"tag\", None))\n",
    "        \n",
    "    return hashtags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba1b96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_from_user(user):\n",
    "    \n",
    "    location = user.get(\"location\", None)\n",
    "    \n",
    "    if location:\n",
    "        geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "        parsed_location = geolocator.geocode(location, addressdetails=True)\n",
    "        if parsed_location:\n",
    "            address = parsed_location.raw[\"address\"]\n",
    "            country = address.get(\"country\", None)\n",
    "            state = address.get(\"state\", None)  \n",
    "            \n",
    "            return (location, country, state)\n",
    "    else:\n",
    "        return (None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c000a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(user_id: str):\n",
    "    url = 'https://api.twitter.com/2/users'\n",
    "    params = {\n",
    "        'ids': user_id,\n",
    "        'user.fields': 'location,public_metrics'\n",
    "    }\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {get_bearer_token()}'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)  \n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200 and \"errors\" not in response.json():\n",
    "        data = response.json()[\"data\"][0]\n",
    "        return data\n",
    "    elif response.status_code == 429:\n",
    "        print(\"Falling asleep for 15 minutes...\")\n",
    "        time.sleep(960)\n",
    "        return get_user(user_id)\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec98911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(tweet_id: str):\n",
    "    url = 'https://api.twitter.com/2/tweets'\n",
    "    params = {\n",
    "        'ids': tweet_id,\n",
    "        'tweet.fields': 'referenced_tweets,author_id,created_at,public_metrics,entities'\n",
    "    }\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {get_bearer_token()}'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200 and \"errors\" not in response.json():\n",
    "        data = response.json()[\"data\"][0]\n",
    "        if \"referenced_tweets\" in data:\n",
    "            return get_tweet(data[\"referenced_tweets\"][0][\"id\"])\n",
    "        else:\n",
    "            return data\n",
    "    elif response.status_code == 429:\n",
    "        print(\"Falling asleep for 15 minutes...\")\n",
    "        time.sleep(960)\n",
    "        return get_tweet(tweet_id)\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dac5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_row(data: map):\n",
    "    try:\n",
    "        created_at = data[\"created_at\"]\n",
    "        tweet_id = data[\"id\"]\n",
    "        user_id =data[\"author_id\"]\n",
    "        text = data[\"text\"]\n",
    "        retweets_count = data[\"public_metrics\"][\"retweet_count\"]\n",
    "        likes_count = data[\"public_metrics\"][\"like_count\"]\n",
    "        replies_count = data[\"public_metrics\"][\"reply_count\"]\n",
    "        hashtags = data[\"entities\"].get(\"hashtags\", None)\n",
    "        hashtags_text = None\n",
    "        if hashtags:\n",
    "            hashtags_text = get_hashtags_texts(hashtags)\n",
    "        url = get_external_url_from_tweet(data)\n",
    "        tweet_trust_score = get_tweet_trust_score(url)\n",
    "        user = get_user(user_id)\n",
    "        location, country, state = get_location_from_user(user)\n",
    "        followers_count, tweet_count = get_metrics_from_user(user)\n",
    "\n",
    "        row = {\n",
    "            \"createdAt\": [created_at],\n",
    "            \"tweetId\": [tweet_id],\n",
    "            \"userId\": user_id,\n",
    "            \"user_followers_count\": [followers_count],\n",
    "            \"user_tweet_count\": [tweet_count],\n",
    "            \"location\": [location],\n",
    "            \"country\": [country],\n",
    "            \"state\": [state],\n",
    "            \"text\": [text],\n",
    "            \"retweetsCount\": [retweets_count],\n",
    "            \"likesCount\": [likes_count],\n",
    "            \"repliesCount\": [replies_count],\n",
    "            \"hashtags\": [hashtags_text],\n",
    "            \"url\": [url],\n",
    "            \"tweetTrustScore\": [tweet_trust_score]\n",
    "        }\n",
    "        \n",
    "        return row\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e4e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_files():\n",
    "    return listdir(SAMPLES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a15e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_rows_from_tweetIds(df, tweetIds: list):\n",
    "    for i, tweet_id in enumerate(lines):\n",
    "        tweet_id = tweet_id.strip()\n",
    "        data = get_tweet(tweet_id)\n",
    "        if data:\n",
    "            row = get_sample_row(data)\n",
    "            if row:\n",
    "                new_df = pd.DataFrame(row)\n",
    "                df = pd.concat([df, new_df], ignore_index=True)\n",
    "        if i == MAX_SAMPLES: break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ff845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2023-02_tweet_ids.txt is being processed...\n",
      "'entities'\n",
      "File 2023-01_tweet_ids.txt is being processed...\n"
     ]
    }
   ],
   "source": [
    "samples_files = get_samples_files()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file_name in samples_files:\n",
    "    sample_file_path = os.path.join(SAMPLES_DIR, file_name)\n",
    "    print(\"File \"+file_name+\" is being processed...\")\n",
    "    with open(sample_file_path) as sample_file:\n",
    "        lines = sample_file.readlines()\n",
    "        df = collect_rows_from_tweetIds(df, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68923edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"collected_samples.csv\", quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287c8be",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f7d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet: str):\n",
    "    tweet = p.clean(tweet)\n",
    "    tweet = tweet.replace('\\d+', '')\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71759208",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/media/vangelis/vag/sentiment_amalysis_final\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "\n",
    "SAMPLES_DIR = \"/home/vangelis/Downloads\"\n",
    "data = pd.read_csv(os.path.join(SAMPLES_DIR, \"tweets.csv\"), index_col=False)\n",
    "texts = list(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f22c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9665/9665 [35:23<00:00,  4.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(texts))):\n",
    "    text = texts[i]\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "    text = preprocess_tweet(text)\n",
    "    result = classifier(text)[0][\"label\"]\n",
    "    label = 1 if result=='LABEL_1' else 0\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac149c1-4bb8-443c-8b8d-ebb2bf2c6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentimentLabel\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc487cc8-0096-43f9-aa37-ac5553f5bcfd",
   "metadata": {},
   "source": [
    "# Subjectivity Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d5e1ed-9c49-4cf6-8d75-b885c290598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_DIR = \"/home/vangelis/PycharmProjects/veritas-observatory/veritas-api/data\"\n",
    "data = pd.read_csv(os.path.join(SAMPLES_DIR, \"verity_dataset.csv\"), index_col=False)\n",
    "data = data.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "901a440a-1fd4-48ae-b36f-07e3684390fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_subjectivity(text):\n",
    "    url = \"http://snf-38872.ok-kno.grnetcloud.net:5051/subjectivity\"\n",
    "    data = {\"text\": text}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "\n",
    "        # Check if the request was successful (HTTP status code 200)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result[\"result\"]\n",
    "        else:\n",
    "            print(f\"HTTP request failed with status code: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d936d81b-0733-412e-bb16-ae46d2c90037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9665/9665 [31:43<00:00,  5.08it/s]\n"
     ]
    }
   ],
   "source": [
    "subjectivity_labels = []\n",
    "for i in tqdm(range(0, len(texts))):\n",
    "    text = texts[i]\n",
    "    score = analyze_subjectivity(text)\n",
    "    subjectivity_labels.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1c98338-d585-41f4-84f6-d768a378d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in subjectivity_labels:\n",
    "    if result is None:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f249c0-a6ef-42e4-b1b0-723b1e759557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>tweetId</th>\n",
       "      <th>userId</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_tweet_count</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>text</th>\n",
       "      <th>retweetsCount</th>\n",
       "      <th>likesCount</th>\n",
       "      <th>repliesCount</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>url</th>\n",
       "      <th>tweetTrustScore</th>\n",
       "      <th>sentimentLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-03T16:52:05.000Z</td>\n",
       "      <td>1345774948086902787</td>\n",
       "      <td>844486678324658176</td>\n",
       "      <td>601753</td>\n",
       "      <td>11601</td>\n",
       "      <td>KwaZulu Natal, South Africa</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>KwaZulu-Natal</td>\n",
       "      <td>We have always said the second wave is going t...</td>\n",
       "      <td>265</td>\n",
       "      <td>1022</td>\n",
       "      <td>816</td>\n",
       "      <td>['VaccineStrategy']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02T19:30:27.000Z</td>\n",
       "      <td>1345452412723752962</td>\n",
       "      <td>84035041</td>\n",
       "      <td>207796</td>\n",
       "      <td>40672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So all the bad covid things me &amp;amp; others we...</td>\n",
       "      <td>4129</td>\n",
       "      <td>14979</td>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03T16:46:34.000Z</td>\n",
       "      <td>1345773561269649408</td>\n",
       "      <td>17143007</td>\n",
       "      <td>91401</td>\n",
       "      <td>22769</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York</td>\n",
       "      <td>Vaccination in New York City is basically only...</td>\n",
       "      <td>4246</td>\n",
       "      <td>21606</td>\n",
       "      <td>765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-03T17:24:41.000Z</td>\n",
       "      <td>1345783152158121984</td>\n",
       "      <td>232268199</td>\n",
       "      <td>2275739</td>\n",
       "      <td>30258</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York</td>\n",
       "      <td>COVID showed that racism is a public health cr...</td>\n",
       "      <td>718</td>\n",
       "      <td>5728</td>\n",
       "      <td>984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-04T00:35:09.000Z</td>\n",
       "      <td>1345891482385997831</td>\n",
       "      <td>1652541</td>\n",
       "      <td>25716233</td>\n",
       "      <td>1016058</td>\n",
       "      <td>Around the world</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>U.S. may cut some Moderna vaccine doses in hal...</td>\n",
       "      <td>58</td>\n",
       "      <td>105</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reut.rs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  createdAt              tweetId              userId   \n",
       "0  2021-01-03T16:52:05.000Z  1345774948086902787  844486678324658176  \\\n",
       "1  2021-01-02T19:30:27.000Z  1345452412723752962            84035041   \n",
       "2  2021-01-03T16:46:34.000Z  1345773561269649408            17143007   \n",
       "3  2021-01-03T17:24:41.000Z  1345783152158121984           232268199   \n",
       "4  2021-01-04T00:35:09.000Z  1345891482385997831             1652541   \n",
       "\n",
       "   user_followers_count  user_tweet_count                     location   \n",
       "0                601753             11601  KwaZulu Natal, South Africa  \\\n",
       "1                207796             40672                          NaN   \n",
       "2                 91401             22769                Manhattan, NY   \n",
       "3               2275739             30258                     New York   \n",
       "4              25716233           1016058             Around the world   \n",
       "\n",
       "         country             state   \n",
       "0   South Africa     KwaZulu-Natal  \\\n",
       "1            NaN               NaN   \n",
       "2  United States          New York   \n",
       "3  United States          New York   \n",
       "4         Canada  British Columbia   \n",
       "\n",
       "                                                text  retweetsCount   \n",
       "0  We have always said the second wave is going t...            265  \\\n",
       "1  So all the bad covid things me &amp; others we...           4129   \n",
       "2  Vaccination in New York City is basically only...           4246   \n",
       "3  COVID showed that racism is a public health cr...            718   \n",
       "4  U.S. may cut some Moderna vaccine doses in hal...             58   \n",
       "\n",
       "   likesCount  repliesCount             hashtags      url  tweetTrustScore   \n",
       "0        1022           816  ['VaccineStrategy']      NaN                0  \\\n",
       "1       14979           257                  NaN      NaN                0   \n",
       "2       21606           765                  NaN      NaN                0   \n",
       "3        5728           984                  NaN      NaN                0   \n",
       "4         105            39                  NaN  reut.rs                0   \n",
       "\n",
       "   sentimentLabel  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14aaac0f-7d1e-4ea6-9bbe-1ea74d8f453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"subjectivityLabel\"] = subjectivity_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d86f3a13-aad2-4a5c-93d5-fc2eceb4acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"final_dataset2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1c551-fe4c-43e3-b0a8-66f44a5091d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
